{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fazeci/QA_with_rag/blob/main/QA_with_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRedUmmwDmPL",
        "outputId": "fb2340ae-903a-413d-dfca-4372bfc16e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38.49.82.243 - - [06/Aug/2024:02:02:23 +0000] \"OPTIONS /products HTTP/1.1\" 302 490\n",
            "191.135.70.33 - - [09/Aug/2024:22:31:04 +0000] \"GET /login HTTP/1.1\" 502 1895\n",
            "87.78.32.79 - - [03/Aug/2024:11:31:52 +0000] \"GET /contact.html HTTP/1.1\" 500 1927\n",
            "169.219.90.71 - - [18/Jul/2024:23:58:13 +0000] \"CONNECT /index.html HTTP/1.1\" 400 1912\n",
            "73.6.108.103 - - [18/Jul/2024:01:27:52 +0000] \"GET /admin HTTP/1.1\" 200 1240\n",
            "216.37.84.199 - - [05/Aug/2024:21:23:39 +0000] \"POST /login HTTP/1.1\" 302 1854\n",
            "211.239.226.126 - - [17/Jul/2024:18:35:50 +0000] \"OPTIONS /index.html HTTP/1.1\" 401 2260\n",
            "15.175.236.243 - - [05/Aug/2024:16:35:36 +0000] \"PUT /login HTTP/1.1\" 301 1577\n",
            "159.160.84.146 - - [09/Aug/2024:23:23:38 +0000] \"PUT /products HTTP/1.1\" 200 947\n",
            "119.225.64.219 - - [17/Jul/2024:10:15:12 +0000] \"GET /contact.html HTTP/1.1\" 404 1021\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import datetime\n",
        "import numpy as np\n",
        "\n",
        "# Normal dağılım kullanarak yanıt boyutunu üretme\n",
        "def generate_normal_distribution_size(mean, std_dev):\n",
        "    return max(0, int(np.random.normal(mean, std_dev)))\n",
        "\n",
        "# Rastgele bir tarih oluşturma (son 30 gün içinde)\n",
        "def generate_random_timestamp():\n",
        "    end_time = datetime.datetime.now()\n",
        "    start_time = end_time - datetime.timedelta(days=30)\n",
        "    random_time = start_time + (end_time - start_time) * random.random()\n",
        "    return random_time\n",
        "\n",
        "# Apache log formatına uygun sahte veriler oluşturma\n",
        "def generate_fake_apache_log_entry():\n",
        "    ip = \".\".join(map(str, random.sample(range(1, 256), 4)))\n",
        "    timestamp = generate_random_timestamp()\n",
        "    method = random.choice(['GET', 'POST', 'PUT', 'DELETE', 'HEAD', 'OPTIONS', 'PATCH', 'CONNECT', 'TRACE'])\n",
        "    uri = random.choice(['/index.html', '/about.html', '/contact.html', '/login', '/products', '/api/data', '/admin'])\n",
        "    protocol = \"HTTP/1.1\"\n",
        "    status = random.choice([200, 201, 204, 301, 302, 304, 400, 401, 403, 404, 500, 502, 503, 504])\n",
        "    size = generate_normal_distribution_size(mean=1500, std_dev=500)\n",
        "\n",
        "    log_entry = f'{ip} - - [{timestamp.strftime(\"%d/%b/%Y:%H:%M:%S +0000\")}] \"{method} {uri} {protocol}\" {status} {size}'\n",
        "    return log_entry\n",
        "\n",
        "# Belirli bir sayıda sahte log verisi oluşturma ve dosyaya yazma\n",
        "def generate_and_save_fake_logs(num_entries, filename='fake_apache_logs.txt'):\n",
        "    fake_logs = [generate_fake_apache_log_entry() for _ in range(num_entries)]\n",
        "\n",
        "    with open(filename, 'w') as file:\n",
        "        for entry in fake_logs:\n",
        "            file.write(entry + '\\n')\n",
        "\n",
        "# Kullanım\n",
        "generate_and_save_fake_logs(1000)\n",
        "\n",
        "# İlk 1000 log verisini görüntüleme\n",
        "with open('fake_apache_logs.txt', 'r') as file:\n",
        "    logs_to_display = [next(file) for _ in range(10)]\n",
        "    print(\"\".join(logs_to_display))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M41ZpAGeDzBO",
        "outputId": "d0dea235-4178-48c5-bc43-bf3781a68b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              ip                   timestamp   method            uri  \\\n",
            "0   38.49.82.243  06/Aug/2024:02:02:23 +0000  OPTIONS      /products   \n",
            "1  191.135.70.33  09/Aug/2024:22:31:04 +0000      GET         /login   \n",
            "2    87.78.32.79  03/Aug/2024:11:31:52 +0000      GET  /contact.html   \n",
            "3  169.219.90.71  18/Jul/2024:23:58:13 +0000  CONNECT    /index.html   \n",
            "4   73.6.108.103  18/Jul/2024:01:27:52 +0000      GET         /admin   \n",
            "\n",
            "   protocol status  size  \n",
            "0  HTTP/1.1    302   490  \n",
            "1  HTTP/1.1    502  1895  \n",
            "2  HTTP/1.1    500  1927  \n",
            "3  HTTP/1.1    400  1912  \n",
            "4  HTTP/1.1    200  1240  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   ip         1000 non-null   object\n",
            " 1   timestamp  1000 non-null   object\n",
            " 2   method     1000 non-null   object\n",
            " 3   uri        1000 non-null   object\n",
            " 4   protocol   1000 non-null   object\n",
            " 5   status     1000 non-null   object\n",
            " 6   size       1000 non-null   object\n",
            "dtypes: object(7)\n",
            "memory usage: 54.8+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Log dosyasını oku\n",
        "log_file_path = '/content/fake_apache_logs.txt'\n",
        "\n",
        "# Apache/Nginx log formatını regex ile ayıklama\n",
        "log_pattern = r'(?P<ip>\\d+\\.\\d+\\.\\d+\\.\\d+)\\s+\\S+\\s+\\S+\\s+\\[(?P<timestamp>.*?)\\]\\s+\"(?P<method>\\S+)\\s+(?P<uri>\\S+)\\s+(?P<protocol>\\S+)\"\\s+(?P<status>\\d+)\\s+(?P<size>\\d+)'\n",
        "\n",
        "# Logları DataFrame'e yükle\n",
        "log_df = pd.read_csv(log_file_path, sep='|', names=['log_entry'])\n",
        "log_df = log_df['log_entry'].str.extract(log_pattern)\n",
        "\n",
        "# Temel analiz\n",
        "print(log_df.head())\n",
        "print(log_df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcf9yXJyD54n",
        "outputId": "943f12c6-8608-4234-e488-150c8010c8a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ip                   object\n",
            "timestamp    datetime64[ns]\n",
            "method               object\n",
            "uri                  object\n",
            "protocol             object\n",
            "status                int64\n",
            "size                  int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Veri türlerini dönüştürme\n",
        "log_df['timestamp'] = pd.to_datetime(log_df['timestamp'], format='%d/%b/%Y:%H:%M:%S +0000')\n",
        "log_df['status'] = log_df['status'].astype(int)\n",
        "log_df['size'] = log_df['size'].astype(int)\n",
        "\n",
        "print(log_df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuDhDnvpEK-5",
        "outputId": "2ab806b1-4b71-4605-d34a-b7c9378c82f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geçersiz status kayıtları: 0\n",
            "Geçersiz size kayıtları: 0\n"
          ]
        }
      ],
      "source": [
        "# Geçersiz (olumsuz) status kodları veya size değerlerini kontrol etme\n",
        "invalid_status = log_df[~log_df['status'].between(100, 599)]  # HTTP status kodları 100-599 aralığındadır\n",
        "invalid_size = log_df[log_df['size'] < 0]  # Boyutun negatif olmaması gerekir\n",
        "\n",
        "print(f\"Geçersiz status kayıtları: {len(invalid_status)}\")\n",
        "print(f\"Geçersiz size kayıtları: {len(invalid_size)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dGJPpAx6yEFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z_xbZfbZyEHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fW-yVEBRyELC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5qjeQQIETSa",
        "outputId": "bf80d94f-30c2-48b9-980c-916eaf13d655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "import faiss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxcHPnWwyLQo",
        "outputId": "dc2f3795-b969-4568-d6ed-a919207568fa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "\n",
        "# Modeli yükle\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
        "\n",
        "\n",
        "# Log verisini birleştirerek metin formatında kullanıma hazırlama\n",
        "log_df['log_text'] = log_df.apply(lambda row: f\"{row['method']} {row['uri']} {row['status']}\", axis=1)\n",
        "\n",
        "# Vektörlere dönüştürme\n",
        "log_vectors = model.encode(log_df['log_text'].tolist(), show_progress_bar=True)\n",
        "\n",
        "# FAISS ile vektörleri bir veri tabanında depolama\n",
        "index = faiss.IndexFlatL2(log_vectors.shape[1])  # L2 mesafe metriği\n",
        "# Vektörleri endekse ekleme\n",
        "index.add(np.array(log_vectors, dtype='float32'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "8f5dca03a5d645608f06b848e442f869",
            "1981a8faf8bb41d09c1534d081f4e2b6",
            "08e9d3a23329492e99a29cef656f8788",
            "49c677d47dbf44dc881493b6c91c0058",
            "30ee1331440e45829bafda3559208746",
            "a7a5e452e7694da49751c4afd8d9ec79",
            "a7e6e6e984fb48989ae5633a31ce7f59",
            "9dce9e3d4726410ebedcad5ed5da5486",
            "5a4d8bae6259493cb79a930326861ad0",
            "c0dcc2a787244d3182242132faec7d47",
            "c8baa341911e4299809494499978d31f"
          ]
        },
        "id": "x1SeJYHBwLGM",
        "outputId": "4bc21884-93d8-4909-b280-387c4201a7fa"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f5dca03a5d645608f06b848e442f869"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_related_logs(query):\n",
        "    \"\"\"\n",
        "    Kullanıcı sorgusuna en benzer log kayıtlarını bulur.\n",
        "    \"\"\"\n",
        "    query_vec = model.encode([query], show_progress_bar=False)\n",
        "    distances, indices = index.search(np.array(query_vec, dtype='float32'), k=4)\n",
        "    return log_df.iloc[indices[0]]\n",
        "\n",
        "\n",
        "def generate_answer(query, related_logs):\n",
        "    \"\"\"\n",
        "    `roberta-base` veya başka bir model kullanarak benzer log kayıtlarından bir yanıt oluşturur.\n",
        "    \"\"\"\n",
        "    if related_logs.empty:\n",
        "        return \"No similar log entries found.\"\n",
        "\n",
        "    # Bağlamı oluşturma\n",
        "    context = \"\\n\".join([\n",
        "        f\"On {row['timestamp']}, a {row['method']} request to {row['uri']} resulted in a {row['status']} status code.\"\n",
        "        for _, row in related_logs.iterrows()\n",
        "    ])\n",
        "\n",
        "    print(\"Context for the question:\\n\", context)  # Bağlamı kontrol et\n",
        "\n",
        "    # Yanıt oluşturma\n",
        "    result = qa_pipeline(\n",
        "        question=query,\n",
        "        context=context,\n",
        "        max_length=150,  # Uzunluğu ihtiyaca göre ayarlayın\n",
        "        num_beams=5,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    return result.get('answer', 'Unable to generate an answer.')\n",
        "\n",
        "def main():\n",
        "    while True:\n",
        "        query = input(\"Enter your query ('q' to quit): \")\n",
        "        if query.lower() == 'q':\n",
        "            break\n",
        "\n",
        "        related_logs = get_related_logs(query)\n",
        "        answer = generate_answer(query, related_logs)\n",
        "\n",
        "        print(\"\\nQuery:\", query)\n",
        "        if not related_logs.empty:\n",
        "            print(\"Related Logs:\\n\", related_logs.to_string(index=False))\n",
        "        else:\n",
        "            print(\"No similar logs found.\")\n",
        "        print(\"Answer:\", answer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbbyXLSv0a5l",
        "outputId": "6e03ca3c-e6c5-48ec-907a-7f9c746df702"
      },
      "execution_count": 62,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query ('q' to quit): when was the last time code 200 was received?\n",
            "Context for the question:\n",
            " On 2024-08-10 17:09:34, a PATCH request to /products resulted in a 200 status code.\n",
            "On 2024-08-09 17:10:56, a PATCH request to /products resulted in a 200 status code.\n",
            "On 2024-08-14 11:46:47, a GET request to /products resulted in a 201 status code.\n",
            "On 2024-08-09 21:16:30, a PATCH request to /products resulted in a 201 status code.\n",
            "\n",
            "Query: when was the last time code 200 was received?\n",
            "Related Logs:\n",
            "             ip           timestamp method       uri protocol  status  size            log_text\n",
            "  97.8.232.102 2024-08-10 17:09:34  PATCH /products HTTP/1.1     200  1269 PATCH /products 200\n",
            "107.34.149.152 2024-08-09 17:10:56  PATCH /products HTTP/1.1     200  2360 PATCH /products 200\n",
            " 73.58.182.238 2024-08-14 11:46:47    GET /products HTTP/1.1     201  2134   GET /products 201\n",
            "104.198.158.45 2024-08-09 21:16:30  PATCH /products HTTP/1.1     201  1630 PATCH /products 201\n",
            "Answer: 2024-08-09 17:10:56\n",
            "Enter your query ('q' to quit):  #What was the most common URI in the last month?\n",
            "Context for the question:\n",
            " On 2024-07-26 13:47:09, a GET request to /index.html resulted in a 201 status code.\n",
            "On 2024-07-18 15:36:36, a GET request to /index.html resulted in a 201 status code.\n",
            "On 2024-08-07 13:14:52, a GET request to /index.html resulted in a 200 status code.\n",
            "On 2024-07-30 16:04:03, a GET request to /index.html resulted in a 200 status code.\n",
            "\n",
            "Query:  #What was the most common URI in the last month?\n",
            "Related Logs:\n",
            "              ip           timestamp method         uri protocol  status  size            log_text\n",
            " 205.148.65.237 2024-07-26 13:47:09    GET /index.html HTTP/1.1     201  1152 GET /index.html 201\n",
            "   72.114.3.254 2024-07-18 15:36:36    GET /index.html HTTP/1.1     201   711 GET /index.html 201\n",
            "   116.80.85.25 2024-08-07 13:14:52    GET /index.html HTTP/1.1     200  1062 GET /index.html 200\n",
            "248.183.230.215 2024-07-30 16:04:03    GET /index.html HTTP/1.1     200  1649 GET /index.html 200\n",
            "Answer: 201\n",
            "Enter your query ('q' to quit):  #What was the most common HTTP method used \n",
            "Context for the question:\n",
            " On 2024-07-26 12:07:11, a OPTIONS request to /index.html resulted in a 400 status code.\n",
            "On 2024-07-20 22:17:41, a GET request to /contact.html resulted in a 400 status code.\n",
            "On 2024-08-04 23:15:40, a GET request to /index.html resulted in a 400 status code.\n",
            "On 2024-08-02 10:21:54, a GET request to /index.html resulted in a 400 status code.\n",
            "\n",
            "Query:  #What was the most common HTTP method used \n",
            "Related Logs:\n",
            "              ip           timestamp  method           uri protocol  status  size                log_text\n",
            "   103.22.13.83 2024-07-26 12:07:11 OPTIONS   /index.html HTTP/1.1     400  1842 OPTIONS /index.html 400\n",
            "143.238.158.142 2024-07-20 22:17:41     GET /contact.html HTTP/1.1     400  1856   GET /contact.html 400\n",
            " 222.245.193.22 2024-08-04 23:15:40     GET   /index.html HTTP/1.1     400   950     GET /index.html 400\n",
            " 164.42.240.181 2024-08-02 10:21:54     GET   /index.html HTTP/1.1     400  1371     GET /index.html 400\n",
            "Answer: OPTIONS request to /index.html\n",
            "Enter your query ('q' to quit):  #What was the most common HTTP method used in the last week?\n",
            "Context for the question:\n",
            " On 2024-07-26 12:07:11, a OPTIONS request to /index.html resulted in a 400 status code.\n",
            "On 2024-08-08 13:20:48, a OPTIONS request to /index.html resulted in a 304 status code.\n",
            "On 2024-07-22 01:55:23, a TRACE request to /about.html resulted in a 400 status code.\n",
            "On 2024-08-04 23:15:40, a GET request to /index.html resulted in a 400 status code.\n",
            "\n",
            "Query:  #What was the most common HTTP method used in the last week?\n",
            "Related Logs:\n",
            "             ip           timestamp  method         uri protocol  status  size                log_text\n",
            "  103.22.13.83 2024-07-26 12:07:11 OPTIONS /index.html HTTP/1.1     400  1842 OPTIONS /index.html 400\n",
            "244.13.237.114 2024-08-08 13:20:48 OPTIONS /index.html HTTP/1.1     304  1181 OPTIONS /index.html 304\n",
            " 238.121.27.70 2024-07-22 01:55:23   TRACE /about.html HTTP/1.1     400  1374   TRACE /about.html 400\n",
            "222.245.193.22 2024-08-04 23:15:40     GET /index.html HTTP/1.1     400   950     GET /index.html 400\n",
            "Answer: OPTIONS request to /index.html\n",
            "Enter your query ('q' to quit): #What is the status of the latest log entry?\n",
            "Context for the question:\n",
            " On 2024-08-08 22:42:45, a TRACE request to /login resulted in a 201 status code.\n",
            "On 2024-07-30 03:08:19, a TRACE request to /login resulted in a 503 status code.\n",
            "On 2024-08-08 22:44:11, a TRACE request to /login resulted in a 504 status code.\n",
            "On 2024-07-18 09:20:40, a TRACE request to /login resulted in a 502 status code.\n",
            "\n",
            "Query: #What is the status of the latest log entry?\n",
            "Related Logs:\n",
            "            ip           timestamp method    uri protocol  status  size         log_text\n",
            "  115.15.7.38 2024-08-08 22:42:45  TRACE /login HTTP/1.1     201  1675 TRACE /login 201\n",
            "147.37.220.26 2024-07-30 03:08:19  TRACE /login HTTP/1.1     503  1825 TRACE /login 503\n",
            " 53.3.125.136 2024-08-08 22:44:11  TRACE /login HTTP/1.1     504  1016 TRACE /login 504\n",
            "252.1.128.236 2024-07-18 09:20:40  TRACE /login HTTP/1.1     502  1060 TRACE /login 502\n",
            "Answer: 201\n",
            "Enter your query ('q' to quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#when was the last time code 200 was received?\n",
        "#What was the most common URI in the last month?\n",
        "#What was the most common HTTP method used in the last week?\n",
        "#What is the status of the latest log entry?\n",
        "#What was the most common error code in the last week?\n",
        "#Which method has the highest average request size?\n",
        "#What is the average response time for each HTTP status code?\n",
        "#what people do most on this site\n",
        "#Which HTTP method was used most frequently in the last week?\n",
        "#What was the most common error code in the logs for the past month?\n",
        "#When was the last time a 500 error code occurred?\n",
        "#Which URI received the most requests in the last 24 hours?\n"
      ],
      "metadata": {
        "id": "4CGEAmLC02nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En sık kullanılanlarıanaliz etme\n",
        "counts = log_df['status'].value_counts()\n",
        "print(counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qKQvZdrQCXU",
        "outputId": "d53aa624-1a0e-45dd-f81c-f8ae813fc508"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "status\n",
            "302    85\n",
            "201    82\n",
            "404    77\n",
            "304    77\n",
            "504    77\n",
            "500    73\n",
            "503    73\n",
            "403    72\n",
            "502    71\n",
            "204    65\n",
            "400    64\n",
            "200    64\n",
            "301    63\n",
            "401    57\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyroN7FbHisD"
      },
      "source": [
        "**Proje Raporu: Log Verileri Üzerinde RAG Modeli ile Sorgu Yanıtlama Sistemi**\n",
        "\n",
        "***1. Giriş***\n",
        "\n",
        "*Projenin Amacı:*\n",
        "Bu proje, web trafik log verilerini kullanarak kullanıcı sorgularına uygun yanıtlar veren bir Retrieval-Augmented Generation (RAG) sistemi geliştirmeyi amaçlamaktadır. Sistem, log verileri üzerinde arama yaparak en uygun kayıtları bulmakta ve bu kayıtları kullanarak jeneratif bir dil modeli ile kullanıcıya yanıt oluşturmaktadır.\n",
        "\n",
        "*Kullanılan Veri Seti:*\n",
        "- Apache log verileri\n",
        "- 100,000 satırlık örnek log kayıtları (IP adresleri, erişilen sayfalar, zaman damgaları vb.)\n",
        "\n",
        "***2. Metodoloji***\n",
        "\n",
        "*Aşama 1: Veri Hazırlığı ve Ön İşleme*\n",
        "- Veri Analizi: Log verileri incelendi ve gerekli sütunlar (IP adresi, URI, HTTP metodu, durum kodu vb.) ayıklandı.\n",
        "- Veri Temizleme: Eksik veya hatalı veriler temizlendi ve sütunlar uygun veri türlerine dönüştürüldü.\n",
        "- Vektörleştirme: Log kayıtları, dil modeli kullanılarak vektörlere dönüştürüldü. FAISS kütüphanesi ile bu vektörler sorgulanabilir bir veri tabanına yüklendi.\n",
        "\n",
        "*Aşama 2: RAG Modelinin Kurulumu*\n",
        "- Bilgi Alma Modülü: FAISS kütüphanesi kullanılarak, kullanıcıdan gelen sorguya en benzer log kayıtlarını bulmak üzere bir bilgi alma modülü oluşturuldu.\n",
        "- Jeneratif Modül:`T5` modelini kullanarak, bulunan log kayıtları üzerinde anlamlı yanıtlar oluşturmak için bir jeneratif modül geliştirildi.\n",
        "- Sistem Entegrasyonu: Bilgi alma ve jeneratif modülleri entegre edilerek, tam işlevsel bir RAG modeli oluşturuldu.\n",
        "\n",
        "*Aşama 3: Sistem Entegrasyonu ve Test*\n",
        "- Sistemin Test Edilmesi: Çeşitli kullanıcı sorguları ile sistem test edildi. Yanıtların doğruluğu ve kalitesi değerlendirildi.\n",
        "- Sistem Performansı: Modelin performansı, sorgu süresi ve yanıt kalitesi açısından ölçüldü.\n",
        "\n",
        "***3. Karşılaşılan Zorluklar ve Çözümleri***\n",
        "\n",
        "- Zorluk: Log verilerinin karmaşıklığı ve tekrarlayan bilgiler.\n",
        "  \n",
        "  Çözüm:Veriyi vektörleştirme sürecinde, benzer log kayıtlarını daha iyi işleyebilmek için veri temizliği ve özetleme teknikleri uygulandı.\n",
        "  \n",
        "- Zorluk: Modelin tekrarlayan veya anlamsız yanıtlar üretmesi.\n",
        "  \n",
        "  Çözüm: Modelde `no_repeat_ngram_size` ve `max_new_tokens` parametreleri ayarlandı. Ayrıca, giriş kontekstinin daha anlamlı hale getirilmesi sağlandı.\n",
        "\n",
        "- Zorluk: Veri Türleri ile İlgili Sorunlar\n",
        "  \n",
        "  Çözüm: Veri türlerini uygun hale getirmek için öncelikle her bir sütunun içeriği analiz edildi ve uygun veri türlerine dönüştürüldü.\n",
        "  \n",
        "Zaman Damgaları: timestamp sütunu, datetime formatına dönüştürüldü, böylece zaman bazlı gruplama ve analizler yapılabildi.\n",
        "\n",
        "Durum Kodları ve Yanıt Boyutları: status ve size sütunları, int64 veri türüne dönüştürüldü, böylece sayısal işlemler ve karşılaştırmalar yapılabildi.\n",
        "\n",
        "IP Adresleri: IP adresleri, string formatında bırakıldı, ancak gerektiğinde IP’lerin sınıflandırılması ve gruplandırılması için düzenli ifadeler (regex) kullanıldı.\n",
        "\n",
        "***4. Performans Değerlendirmesi***\n",
        "\n",
        "-Doğruluk: Sistem, kullanıcı sorgularına yanıt verirken doğru ve alakalı log kayıtlarını kullandı. Yanıtlar, log kayıtlarının genel paternlerine uygun şekilde oluşturuldu.\n",
        "-Yanıt Süresi: Sistem, büyük veri setiyle çalışmasına rağmen makul sürelerde yanıt üretebildi. FAISS vektör veri tabanı, yüksek verimli arama sağladı.\n",
        "\n",
        "\n",
        "***5. Sonuç ve Öneriler***\n",
        "\n",
        "* Genel Değerlendirme: Geliştirilen sistem, log verileri üzerinde başarılı bir\n",
        "şekilde sorgu yapabilen ve yanıtlar üretebilen bir RAG modeli olarak çalıştı.\n",
        "\n",
        "* Öneriler: Daha farklı veri türleriyle sistemin test edilmesi, sistemin genelleme yeteneğini artırabilir.\n",
        "\n",
        "* BART, roberta-base ve T5 dil modelleri denendi ancak yanıtların doğruluğunun artırılması için modelin daha çok geliştirilmesi gerekmektedir.\n",
        "\n",
        "***6. Kaynaklar***\n",
        "\n",
        "- Kullanılan kütüphaneler: `transformers`, `sentence-transformers`, `faiss`, `pandas`, `numpy`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_PhsIRUb6nUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FATMA ZEHRA ÇINAR\n"
      ],
      "metadata": {
        "id": "XKzc-Epqqu2y"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBgHbhfLdnBSio96TbdtKh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f5dca03a5d645608f06b848e442f869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1981a8faf8bb41d09c1534d081f4e2b6",
              "IPY_MODEL_08e9d3a23329492e99a29cef656f8788",
              "IPY_MODEL_49c677d47dbf44dc881493b6c91c0058"
            ],
            "layout": "IPY_MODEL_30ee1331440e45829bafda3559208746"
          }
        },
        "1981a8faf8bb41d09c1534d081f4e2b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a5e452e7694da49751c4afd8d9ec79",
            "placeholder": "​",
            "style": "IPY_MODEL_a7e6e6e984fb48989ae5633a31ce7f59",
            "value": "Batches: 100%"
          }
        },
        "08e9d3a23329492e99a29cef656f8788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dce9e3d4726410ebedcad5ed5da5486",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a4d8bae6259493cb79a930326861ad0",
            "value": 32
          }
        },
        "49c677d47dbf44dc881493b6c91c0058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0dcc2a787244d3182242132faec7d47",
            "placeholder": "​",
            "style": "IPY_MODEL_c8baa341911e4299809494499978d31f",
            "value": " 32/32 [00:09&lt;00:00,  4.50it/s]"
          }
        },
        "30ee1331440e45829bafda3559208746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7a5e452e7694da49751c4afd8d9ec79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e6e6e984fb48989ae5633a31ce7f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dce9e3d4726410ebedcad5ed5da5486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a4d8bae6259493cb79a930326861ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0dcc2a787244d3182242132faec7d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8baa341911e4299809494499978d31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}